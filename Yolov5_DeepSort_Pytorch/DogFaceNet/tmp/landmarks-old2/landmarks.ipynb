{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "\n",
    "PATH = '../data/landmarks/'\n",
    "\n",
    "IMAGE_SIZE = (128,128,3)\n",
    "\n",
    "# Limite size of input for testing\n",
    "TEST_LIMIT = 1000\n",
    "\n",
    "SPLIT = 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "STEPS_PER_EPOCH = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(658, 7, 2)\n",
      "(658,)\n",
      "(658,)\n",
      "Loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/658 [00:00<?, ?it/s]c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 658/658 [02:01<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the raw images\n",
    "resized_path = PATH + 'resized/'\n",
    "filenames = os.listdir(resized_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "filename_int = np.sort([int(s[:-4]) for s in filenames])\n",
    "\n",
    "filenames = np.array([resized_path + str(i) + '.jpg' for i in filename_int])\n",
    "\n",
    "# Retrieve the masks\n",
    "masks_path = PATH + 'resized_masks/'\n",
    "f_masks = os.listdir(masks_path)\n",
    "\n",
    "## Sort the filenames in the proper order\n",
    "f_masks_int = np.sort([int(s[:-4]) for s in f_masks])\n",
    "\n",
    "f_masks = np.array([resized_path + str(i) + '.jpg' for i in f_masks_int])\n",
    "\n",
    "# Retrieve the landmarks\n",
    "labels = np.load(PATH + 'resized_labels.npy')\n",
    "\n",
    "# Reshape the outputs\n",
    "print(labels.shape)\n",
    "print(f_masks.shape)\n",
    "print(filenames.shape)\n",
    "assert len(f_masks)==len(labels)\n",
    "assert len(filenames)==len(labels)\n",
    "\n",
    "if TEST_LIMIT>len(labels):\n",
    "    TEST_LIMIT = len(labels)\n",
    "\n",
    "\n",
    "w,h,c = IMAGE_SIZE\n",
    "images = np.empty((0,w,h,c))\n",
    "\n",
    "masks = np.empty((0,w,h,1))\n",
    "\n",
    "print(\"Loading images...\")\n",
    "labels = labels[:TEST_LIMIT]\n",
    "labels = np.reshape(labels,(TEST_LIMIT,14))\n",
    "labels = labels[:,:10]\n",
    "\n",
    "for i in tqdm(range(TEST_LIMIT)):\n",
    "    image = sk.io.imread(filenames[i])\n",
    "    image_resized = sk.transform.resize(image, IMAGE_SIZE)\n",
    "    images = np.vstack((images,np.expand_dims(image_resized,0)))\n",
    "\n",
    "    mask = sk.io.imread(f_masks[i])\n",
    "\n",
    "    mask_resized = sk.transform.resize(mask, (w,h,1))\n",
    "    masks = np.vstack((masks,np.expand_dims(mask_resized,0)))\n",
    "\n",
    "\n",
    "\n",
    "train_split = int(SPLIT*len(labels))\n",
    "\n",
    "images_train = images[:train_split]\n",
    "images_valid = images[train_split:]\n",
    "\n",
    "masks_train = masks[:train_split]\n",
    "masks_valid = masks[train_split:]\n",
    "\n",
    "labels_train = labels[:train_split]\n",
    "labels_valid = labels[train_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try: model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TriNet(ratio=4, input_shape=(128,128,3)):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "     -ratio: ratio of channel reduction in SE module\n",
    "     -imput_shape: input image shape\n",
    "    \"\"\"\n",
    "    \n",
    "    def CBA_layer(x, filters, size=3, depth=2):\n",
    "        \n",
    "        for _ in range(depth):\n",
    "            x = tf.keras.layers.Conv2D(filters, (size, size), padding='same') (x)\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "            x = tf.keras.layers.Activation('relu')(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def Res_layer(x, num_split, filters):\n",
    "        '''\n",
    "        ResNet-like layer\n",
    "        '''\n",
    "        \n",
    "        # Spliting the branches and changing the size of the convolution\n",
    "        splitted_branches = list()\n",
    "        \n",
    "        for i in range(num_split):\n",
    "            if i+1 < 6:\n",
    "                size = i+1 \n",
    "            else:\n",
    "                size = 3\n",
    "            branch = CBA_layer(x, filters, size)\n",
    "            splitted_branches.append(branch)\n",
    "        \n",
    "        x = tf.keras.layers.concatenate(splitted_branches)\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same') (x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def SE_layer(x):\n",
    "        '''\n",
    "        SENet-like layer\n",
    "        '''\n",
    "        out_dim = int(np.shape(x)[-1])\n",
    "        squeeze = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        excitation = tf.keras.layers.Dense(units=out_dim // ratio)(squeeze)\n",
    "        excitation = tf.keras.layers.Activation('relu')(excitation)\n",
    "        excitation = tf.keras.layers.Dense(units=out_dim)(excitation)\n",
    "        excitation = tf.keras.layers.Activation('sigmoid')(excitation)\n",
    "        excitation = tf.keras.layers.Reshape((1,1,out_dim))(excitation)\n",
    "        \n",
    "        scale = tf.keras.layers.multiply([x,excitation])\n",
    "        \n",
    "        return scale\n",
    "    \n",
    "    def RSE_layer(x, num_split, filters):\n",
    "        r = Res_layer(x, num_split, filters)\n",
    "        s = SE_layer(r)\n",
    "        c = tf.keras.layers.concatenate([x,s])\n",
    "        return tf.keras.layers.Activation('relu')(c)\n",
    "    \n",
    "\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "\n",
    "    s = tf.keras.layers.Lambda(lambda x: x / 255) (inputs)\n",
    "    \n",
    "    #Down 1\n",
    "    r1 = RSE_layer(s, 2, 8)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r1)\n",
    "    \n",
    "    #Down 2\n",
    "    r2 = RSE_layer(x, 4, 16)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r2)\n",
    "    \n",
    "    #Down 3\n",
    "    r3 = RSE_layer(x, 4, 32)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r3)\n",
    "    \n",
    "    #Down 4\n",
    "    r4 = RSE_layer(x, 6, 64)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r4)\n",
    "    \n",
    "    #Down 5\n",
    "    r5 = RSE_layer(x, 6, 128)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2)) (r5)\n",
    "    \n",
    "    #Middle\n",
    "    x = RSE_layer(x, 4, 256)\n",
    "\n",
    "    # First branch: landmarks detection\n",
    "    y = CBA_layer(x, 512)\n",
    "    y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
    "    y = tf.keras.layers.Flatten()(y)\n",
    "    y = tf.keras.layers.Dense(10)(y)\n",
    "    landmarks_output = tf.keras.layers.Lambda(lambda x: x * 255, name='landmarks_output')(y)\n",
    "    \n",
    "    # Second branch: mask generation\n",
    "    #Up 1\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r5])\n",
    "    x = RSE_layer(x, 6, 128)\n",
    "    \n",
    "    #Up 2\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r4])\n",
    "    x = RSE_layer(x, 6, 64)\n",
    "    \n",
    "    #Up 3\n",
    "    x = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r3])\n",
    "    x = RSE_layer(x, 4, 32)\n",
    "    \n",
    "    #Up 4\n",
    "    x = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r2])\n",
    "    x = RSE_layer(x, 4, 16)\n",
    "    \n",
    "    #Up 5\n",
    "    x = tf.keras.layers.Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (x)\n",
    "    x = tf.keras.layers.concatenate([x,r1])\n",
    "    x = RSE_layer(x, 2, 8)\n",
    "    \n",
    "    mask_output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name='mask_output') (x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, [landmarks_output, mask_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(y_true,y_pred):\n",
    "    return tf.divide(tf.keras.losses.mse(y_true,y_pred), tf.constant(1000.0))\n",
    "def zero_loss(y_true,y_pred):\n",
    "    return tf.constant(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 3)  0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, 128, 128, 8)  32          lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, 128, 128, 8)  104         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 128, 128, 8)  32          conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 128, 128, 8)  32          conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_524 (Activation)     (None, 128, 128, 8)  0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_526 (Activation)     (None, 128, 128, 8)  0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, 128, 128, 8)  72          activation_524[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, 128, 128, 8)  264         activation_526[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 128, 128, 8)  32          conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 128, 128, 8)  32          conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_525 (Activation)     (None, 128, 128, 8)  0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_527 (Activation)     (None, 128, 128, 8)  0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 128, 128, 16) 0           activation_525[0][0]             \n",
      "                                                                 activation_527[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, 128, 128, 8)  1160        concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 128, 128, 8)  32          conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_48 (Gl (None, 8)            0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 2)            18          global_average_pooling2d_48[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_528 (Activation)     (None, 2)            0           dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 8)            24          activation_528[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_529 (Activation)     (None, 8)            0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_44 (Reshape)            (None, 1, 1, 8)      0           activation_529[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_44 (Multiply)          (None, 128, 128, 8)  0           batch_normalization_440[0][0]    \n",
      "                                                                 reshape_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 128, 128, 11) 0           lambda_4[0][0]                   \n",
      "                                                                 multiply_44[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_530 (Activation)     (None, 128, 128, 11) 0           concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 64, 64, 11)   0           activation_530[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, 64, 64, 16)   192         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, 64, 64, 16)   720         max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, 64, 64, 16)   1600        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, 64, 64, 16)   2832        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 64, 64, 16)   64          conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 64, 64, 16)   64          conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 64, 64, 16)   64          conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 64, 64, 16)   64          conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_531 (Activation)     (None, 64, 64, 16)   0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_533 (Activation)     (None, 64, 64, 16)   0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_535 (Activation)     (None, 64, 64, 16)   0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_537 (Activation)     (None, 64, 64, 16)   0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, 64, 64, 16)   272         activation_531[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, 64, 64, 16)   1040        activation_533[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, 64, 64, 16)   2320        activation_535[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 64, 64, 16)   4112        activation_537[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 64, 64, 16)   64          conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 64, 64, 16)   64          conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 64, 64, 16)   64          conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 64, 64, 16)   64          conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_532 (Activation)     (None, 64, 64, 16)   0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_534 (Activation)     (None, 64, 64, 16)   0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_536 (Activation)     (None, 64, 64, 16)   0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_538 (Activation)     (None, 64, 64, 16)   0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 64, 64, 64)   0           activation_532[0][0]             \n",
      "                                                                 activation_534[0][0]             \n",
      "                                                                 activation_536[0][0]             \n",
      "                                                                 activation_538[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 64, 64, 16)   9232        concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 64, 64, 16)   64          conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_49 (Gl (None, 16)           0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 4)            68          global_average_pooling2d_49[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_539 (Activation)     (None, 4)            0           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 16)           80          activation_539[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_540 (Activation)     (None, 16)           0           dense_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_45 (Reshape)            (None, 1, 1, 16)     0           activation_540[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_45 (Multiply)          (None, 64, 64, 16)   0           batch_normalization_449[0][0]    \n",
      "                                                                 reshape_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 64, 64, 27)   0           max_pooling2d_20[0][0]           \n",
      "                                                                 multiply_45[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_541 (Activation)     (None, 64, 64, 27)   0           concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 32, 32, 27)   0           activation_541[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 32, 32, 32)   896         max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 32, 32, 32)   3488        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 32, 32, 32)   7808        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 32, 32, 32)   13856       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 32, 32, 32)   128         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 32, 32, 32)   128         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 32, 32, 32)   128         conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, 32, 32, 32)   128         conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_542 (Activation)     (None, 32, 32, 32)   0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_544 (Activation)     (None, 32, 32, 32)   0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_546 (Activation)     (None, 32, 32, 32)   0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_548 (Activation)     (None, 32, 32, 32)   0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 32, 32, 32)   1056        activation_542[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 32, 32, 32)   4128        activation_544[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 32, 32, 32)   9248        activation_546[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 32, 32, 32)   16416       activation_548[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 32, 32, 32)   128         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 32, 32, 32)   128         conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 32, 32, 32)   128         conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, 32, 32, 32)   128         conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_543 (Activation)     (None, 32, 32, 32)   0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_545 (Activation)     (None, 32, 32, 32)   0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_547 (Activation)     (None, 32, 32, 32)   0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_549 (Activation)     (None, 32, 32, 32)   0           batch_normalization_457[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 32, 32, 128)  0           activation_543[0][0]             \n",
      "                                                                 activation_545[0][0]             \n",
      "                                                                 activation_547[0][0]             \n",
      "                                                                 activation_549[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 32, 32, 32)   36896       concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, 32, 32, 32)   128         conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_50 (Gl (None, 32)           0           batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 8)            264         global_average_pooling2d_50[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_550 (Activation)     (None, 8)            0           dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 32)           288         activation_550[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_551 (Activation)     (None, 32)           0           dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_46 (Reshape)            (None, 1, 1, 32)     0           activation_551[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_46 (Multiply)          (None, 32, 32, 32)   0           batch_normalization_458[0][0]    \n",
      "                                                                 reshape_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 32, 32, 59)   0           max_pooling2d_21[0][0]           \n",
      "                                                                 multiply_46[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_552 (Activation)     (None, 32, 32, 59)   0           concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 16, 16, 59)   0           activation_552[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 16, 16, 64)   3840        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 16, 16, 64)   15168       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 16, 16, 64)   34048       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 16, 16, 64)   60480       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 16, 16, 64)   94464       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 16, 16, 64)   34048       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, 16, 16, 64)   256         conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, 16, 16, 64)   256         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, 16, 16, 64)   256         conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, 16, 16, 64)   256         conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, 16, 16, 64)   256         conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 16, 16, 64)   256         conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_553 (Activation)     (None, 16, 16, 64)   0           batch_normalization_459[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_555 (Activation)     (None, 16, 16, 64)   0           batch_normalization_461[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_557 (Activation)     (None, 16, 16, 64)   0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_559 (Activation)     (None, 16, 16, 64)   0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_561 (Activation)     (None, 16, 16, 64)   0           batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_563 (Activation)     (None, 16, 16, 64)   0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 16, 16, 64)   4160        activation_553[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 16, 16, 64)   16448       activation_555[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 16, 16, 64)   36928       activation_557[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 16, 16, 64)   65600       activation_559[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 16, 16, 64)   102464      activation_561[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 16, 16, 64)   36928       activation_563[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, 16, 16, 64)   256         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, 16, 16, 64)   256         conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, 16, 16, 64)   256         conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, 16, 16, 64)   256         conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 16, 16, 64)   256         conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 16, 16, 64)   256         conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_554 (Activation)     (None, 16, 16, 64)   0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_556 (Activation)     (None, 16, 16, 64)   0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_558 (Activation)     (None, 16, 16, 64)   0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_560 (Activation)     (None, 16, 16, 64)   0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_562 (Activation)     (None, 16, 16, 64)   0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 16, 16, 64)   0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 16, 16, 384)  0           activation_554[0][0]             \n",
      "                                                                 activation_556[0][0]             \n",
      "                                                                 activation_558[0][0]             \n",
      "                                                                 activation_560[0][0]             \n",
      "                                                                 activation_562[0][0]             \n",
      "                                                                 activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 16, 16, 64)   221248      concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 16, 16, 64)   256         conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_51 (Gl (None, 64)           0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 16)           1040        global_average_pooling2d_51[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_565 (Activation)     (None, 16)           0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 64)           1088        activation_565[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_566 (Activation)     (None, 64)           0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_47 (Reshape)            (None, 1, 1, 64)     0           activation_566[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_47 (Multiply)          (None, 16, 16, 64)   0           batch_normalization_471[0][0]    \n",
      "                                                                 reshape_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 16, 16, 123)  0           max_pooling2d_22[0][0]           \n",
      "                                                                 multiply_47[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_567 (Activation)     (None, 16, 16, 123)  0           concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 8, 8, 123)    0           activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 8, 8, 128)    15872       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 8, 8, 128)    63104       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 8, 8, 128)    141824      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)             (None, 8, 8, 128)    252032      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)             (None, 8, 8, 128)    393728      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)             (None, 8, 8, 128)    141824      max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 8, 8, 128)    512         conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, 8, 8, 128)    512         conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, 8, 8, 128)    512         conv2d_476[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, 8, 8, 128)    512         conv2d_478[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, 8, 8, 128)    512         conv2d_480[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchN (None, 8, 8, 128)    512         conv2d_482[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_568 (Activation)     (None, 8, 8, 128)    0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_570 (Activation)     (None, 8, 8, 128)    0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_572 (Activation)     (None, 8, 8, 128)    0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_574 (Activation)     (None, 8, 8, 128)    0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_576 (Activation)     (None, 8, 8, 128)    0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_578 (Activation)     (None, 8, 8, 128)    0           batch_normalization_482[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 8, 8, 128)    16512       activation_568[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 8, 8, 128)    65664       activation_570[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)             (None, 8, 8, 128)    147584      activation_572[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)             (None, 8, 8, 128)    262272      activation_574[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)             (None, 8, 8, 128)    409728      activation_576[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)             (None, 8, 8, 128)    147584      activation_578[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 8, 8, 128)    512         conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, 8, 8, 128)    512         conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, 8, 8, 128)    512         conv2d_477[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, 8, 8, 128)    512         conv2d_479[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, 8, 8, 128)    512         conv2d_481[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchN (None, 8, 8, 128)    512         conv2d_483[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_569 (Activation)     (None, 8, 8, 128)    0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_571 (Activation)     (None, 8, 8, 128)    0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_573 (Activation)     (None, 8, 8, 128)    0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_575 (Activation)     (None, 8, 8, 128)    0           batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_577 (Activation)     (None, 8, 8, 128)    0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_579 (Activation)     (None, 8, 8, 128)    0           batch_normalization_483[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 8, 8, 768)    0           activation_569[0][0]             \n",
      "                                                                 activation_571[0][0]             \n",
      "                                                                 activation_573[0][0]             \n",
      "                                                                 activation_575[0][0]             \n",
      "                                                                 activation_577[0][0]             \n",
      "                                                                 activation_579[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)             (None, 8, 8, 128)    884864      concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchN (None, 8, 8, 128)    512         conv2d_484[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_52 (Gl (None, 128)          0           batch_normalization_484[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 32)           4128        global_average_pooling2d_52[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_580 (Activation)     (None, 32)           0           dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 128)          4224        activation_580[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_581 (Activation)     (None, 128)          0           dense_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_48 (Reshape)            (None, 1, 1, 128)    0           activation_581[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_48 (Multiply)          (None, 8, 8, 128)    0           batch_normalization_484[0][0]    \n",
      "                                                                 reshape_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 8, 8, 251)    0           max_pooling2d_23[0][0]           \n",
      "                                                                 multiply_48[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_582 (Activation)     (None, 8, 8, 251)    0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 4, 4, 251)    0           activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)             (None, 4, 4, 256)    64512       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)             (None, 4, 4, 256)    257280      max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)             (None, 4, 4, 256)    578560      max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)             (None, 4, 4, 256)    1028352     max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchN (None, 4, 4, 256)    1024        conv2d_485[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchN (None, 4, 4, 256)    1024        conv2d_487[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchN (None, 4, 4, 256)    1024        conv2d_489[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchN (None, 4, 4, 256)    1024        conv2d_491[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 4, 4, 256)    0           batch_normalization_485[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 4, 4, 256)    0           batch_normalization_487[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 4, 4, 256)    0           batch_normalization_489[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 4, 4, 256)    0           batch_normalization_491[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)             (None, 4, 4, 256)    65792       activation_583[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)             (None, 4, 4, 256)    262400      activation_585[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)             (None, 4, 4, 256)    590080      activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)             (None, 4, 4, 256)    1048832     activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchN (None, 4, 4, 256)    1024        conv2d_486[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchN (None, 4, 4, 256)    1024        conv2d_488[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchN (None, 4, 4, 256)    1024        conv2d_490[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchN (None, 4, 4, 256)    1024        conv2d_492[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 4, 4, 256)    0           batch_normalization_486[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 4, 4, 256)    0           batch_normalization_488[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 4, 4, 256)    0           batch_normalization_490[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 4, 4, 256)    0           batch_normalization_492[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 4, 4, 1024)   0           activation_584[0][0]             \n",
      "                                                                 activation_586[0][0]             \n",
      "                                                                 activation_588[0][0]             \n",
      "                                                                 activation_590[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)             (None, 4, 4, 256)    2359552     concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchN (None, 4, 4, 256)    1024        conv2d_493[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_53 (Gl (None, 256)          0           batch_normalization_493[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 64)           16448       global_average_pooling2d_53[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_591 (Activation)     (None, 64)           0           dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 256)          16640       activation_591[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_592 (Activation)     (None, 256)          0           dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 1, 1, 256)    0           activation_592[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_49 (Multiply)          (None, 4, 4, 256)    0           batch_normalization_493[0][0]    \n",
      "                                                                 reshape_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 4, 4, 507)    0           max_pooling2d_24[0][0]           \n",
      "                                                                 multiply_49[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_593 (Activation)     (None, 4, 4, 507)    0           concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTran (None, 8, 8, 128)    259712      activation_593[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 8, 8, 379)    0           conv2d_transpose_20[0][0]        \n",
      "                                                                 activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)             (None, 8, 8, 128)    48640       concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)             (None, 8, 8, 128)    194176      concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)             (None, 8, 8, 128)    436736      concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)             (None, 8, 8, 128)    776320      concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)             (None, 8, 8, 128)    1212928     concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)             (None, 8, 8, 128)    436736      concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchN (None, 8, 8, 128)    512         conv2d_496[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchN (None, 8, 8, 128)    512         conv2d_498[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchN (None, 8, 8, 128)    512         conv2d_500[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchN (None, 8, 8, 128)    512         conv2d_502[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchN (None, 8, 8, 128)    512         conv2d_504[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchN (None, 8, 8, 128)    512         conv2d_506[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 8, 8, 128)    0           batch_normalization_496[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 8, 8, 128)    0           batch_normalization_498[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 8, 8, 128)    0           batch_normalization_500[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 8, 8, 128)    0           batch_normalization_502[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 8, 8, 128)    0           batch_normalization_504[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 8, 8, 128)    0           batch_normalization_506[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)             (None, 8, 8, 128)    16512       activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)             (None, 8, 8, 128)    65664       activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)             (None, 8, 8, 128)    147584      activation_600[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)             (None, 8, 8, 128)    262272      activation_602[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)             (None, 8, 8, 128)    409728      activation_604[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)             (None, 8, 8, 128)    147584      activation_606[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchN (None, 8, 8, 128)    512         conv2d_497[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchN (None, 8, 8, 128)    512         conv2d_499[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchN (None, 8, 8, 128)    512         conv2d_501[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchN (None, 8, 8, 128)    512         conv2d_503[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchN (None, 8, 8, 128)    512         conv2d_505[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchN (None, 8, 8, 128)    512         conv2d_507[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 8, 8, 128)    0           batch_normalization_497[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 8, 8, 128)    0           batch_normalization_499[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 8, 8, 128)    0           batch_normalization_501[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 8, 8, 128)    0           batch_normalization_503[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 8, 8, 128)    0           batch_normalization_505[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 8, 8, 128)    0           batch_normalization_507[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 8, 8, 768)    0           activation_597[0][0]             \n",
      "                                                                 activation_599[0][0]             \n",
      "                                                                 activation_601[0][0]             \n",
      "                                                                 activation_603[0][0]             \n",
      "                                                                 activation_605[0][0]             \n",
      "                                                                 activation_607[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)             (None, 8, 8, 128)    884864      concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchN (None, 8, 8, 128)    512         conv2d_508[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_55 (Gl (None, 128)          0           batch_normalization_508[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 32)           4128        global_average_pooling2d_55[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 32)           0           dense_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 128)          4224        activation_608[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 128)          0           dense_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_50 (Reshape)            (None, 1, 1, 128)    0           activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_50 (Multiply)          (None, 8, 8, 128)    0           batch_normalization_508[0][0]    \n",
      "                                                                 reshape_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 8, 8, 507)    0           concatenate_120[0][0]            \n",
      "                                                                 multiply_50[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 8, 8, 507)    0           concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DTran (None, 16, 16, 64)   129856      activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 16, 16, 187)  0           conv2d_transpose_21[0][0]        \n",
      "                                                                 activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)             (None, 16, 16, 64)   12032       concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)             (None, 16, 16, 64)   47936       concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)             (None, 16, 16, 64)   107776      concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)             (None, 16, 16, 64)   191552      concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)             (None, 16, 16, 64)   299264      concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)             (None, 16, 16, 64)   107776      concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchN (None, 16, 16, 64)   256         conv2d_509[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchN (None, 16, 16, 64)   256         conv2d_511[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchN (None, 16, 16, 64)   256         conv2d_513[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchN (None, 16, 16, 64)   256         conv2d_515[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchN (None, 16, 16, 64)   256         conv2d_517[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchN (None, 16, 16, 64)   256         conv2d_519[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 16, 16, 64)   0           batch_normalization_509[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 16, 16, 64)   0           batch_normalization_511[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 16, 16, 64)   0           batch_normalization_513[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 16, 16, 64)   0           batch_normalization_515[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 16, 16, 64)   0           batch_normalization_517[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 16, 16, 64)   0           batch_normalization_519[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)             (None, 16, 16, 64)   4160        activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)             (None, 16, 16, 64)   16448       activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)             (None, 16, 16, 64)   36928       activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)             (None, 16, 16, 64)   65600       activation_617[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)             (None, 16, 16, 64)   102464      activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)             (None, 16, 16, 64)   36928       activation_621[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchN (None, 16, 16, 64)   256         conv2d_510[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchN (None, 16, 16, 64)   256         conv2d_512[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchN (None, 16, 16, 64)   256         conv2d_514[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchN (None, 16, 16, 64)   256         conv2d_516[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchN (None, 16, 16, 64)   256         conv2d_518[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchN (None, 16, 16, 64)   256         conv2d_520[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 16, 16, 64)   0           batch_normalization_510[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 16, 16, 64)   0           batch_normalization_512[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 16, 16, 64)   0           batch_normalization_514[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 16, 16, 64)   0           batch_normalization_516[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 16, 16, 64)   0           batch_normalization_518[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 16, 16, 64)   0           batch_normalization_520[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 16, 16, 384)  0           activation_612[0][0]             \n",
      "                                                                 activation_614[0][0]             \n",
      "                                                                 activation_616[0][0]             \n",
      "                                                                 activation_618[0][0]             \n",
      "                                                                 activation_620[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)             (None, 16, 16, 64)   221248      concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchN (None, 16, 16, 64)   256         conv2d_521[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_56 (Gl (None, 64)           0           batch_normalization_521[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 16)           1040        global_average_pooling2d_56[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 16)           0           dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 64)           1088        activation_623[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 64)           0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_51 (Reshape)            (None, 1, 1, 64)     0           activation_624[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_51 (Multiply)          (None, 16, 16, 64)   0           batch_normalization_521[0][0]    \n",
      "                                                                 reshape_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 16, 16, 251)  0           concatenate_123[0][0]            \n",
      "                                                                 multiply_51[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 16, 16, 251)  0           concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DTran (None, 32, 32, 32)   32160       activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 32, 32, 91)   0           conv2d_transpose_22[0][0]        \n",
      "                                                                 activation_552[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)             (None, 32, 32, 32)   2944        concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)             (None, 32, 32, 32)   11680       concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)             (None, 32, 32, 32)   26240       concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)             (None, 32, 32, 32)   46624       concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchN (None, 32, 32, 32)   128         conv2d_522[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchN (None, 32, 32, 32)   128         conv2d_524[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchN (None, 32, 32, 32)   128         conv2d_526[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchN (None, 32, 32, 32)   128         conv2d_528[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 32, 32, 32)   0           batch_normalization_522[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 32, 32, 32)   0           batch_normalization_524[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 32, 32, 32)   0           batch_normalization_526[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 32, 32, 32)   0           batch_normalization_528[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)             (None, 32, 32, 32)   1056        activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)             (None, 32, 32, 32)   4128        activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)             (None, 32, 32, 32)   9248        activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)             (None, 32, 32, 32)   16416       activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchN (None, 32, 32, 32)   128         conv2d_523[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchN (None, 32, 32, 32)   128         conv2d_525[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchN (None, 32, 32, 32)   128         conv2d_527[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchN (None, 32, 32, 32)   128         conv2d_529[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 32, 32, 32)   0           batch_normalization_523[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 32, 32, 32)   0           batch_normalization_525[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 32, 32, 32)   0           batch_normalization_527[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 32, 32, 32)   0           batch_normalization_529[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 32, 32, 128)  0           activation_627[0][0]             \n",
      "                                                                 activation_629[0][0]             \n",
      "                                                                 activation_631[0][0]             \n",
      "                                                                 activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)             (None, 32, 32, 32)   36896       concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchN (None, 32, 32, 32)   128         conv2d_530[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_57 (Gl (None, 32)           0           batch_normalization_530[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 8)            264         global_average_pooling2d_57[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 8)            0           dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 32)           288         activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 32)           0           dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_52 (Reshape)            (None, 1, 1, 32)     0           activation_635[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_52 (Multiply)          (None, 32, 32, 32)   0           batch_normalization_530[0][0]    \n",
      "                                                                 reshape_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 32, 32, 123)  0           concatenate_126[0][0]            \n",
      "                                                                 multiply_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 32, 32, 123)  0           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DTran (None, 64, 64, 16)   7888        activation_636[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 64, 64, 43)   0           conv2d_transpose_23[0][0]        \n",
      "                                                                 activation_541[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)             (None, 64, 64, 16)   704         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)             (None, 64, 64, 16)   2768        concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)             (None, 64, 64, 16)   6208        concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)             (None, 64, 64, 16)   11024       concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchN (None, 64, 64, 16)   64          conv2d_531[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchN (None, 64, 64, 16)   64          conv2d_533[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchN (None, 64, 64, 16)   64          conv2d_535[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchN (None, 64, 64, 16)   64          conv2d_537[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 64, 64, 16)   0           batch_normalization_531[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 64, 64, 16)   0           batch_normalization_533[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 64, 64, 16)   0           batch_normalization_535[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 64, 64, 16)   0           batch_normalization_537[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)             (None, 64, 64, 16)   272         activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)             (None, 64, 64, 16)   1040        activation_639[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)             (None, 64, 64, 16)   2320        activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)             (None, 64, 64, 16)   4112        activation_643[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchN (None, 64, 64, 16)   64          conv2d_532[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchN (None, 64, 64, 16)   64          conv2d_534[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchN (None, 64, 64, 16)   64          conv2d_536[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchN (None, 64, 64, 16)   64          conv2d_538[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 64, 64, 16)   0           batch_normalization_532[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 64, 64, 16)   0           batch_normalization_534[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 64, 64, 16)   0           batch_normalization_536[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 64, 64, 16)   0           batch_normalization_538[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 64, 64, 64)   0           activation_638[0][0]             \n",
      "                                                                 activation_640[0][0]             \n",
      "                                                                 activation_642[0][0]             \n",
      "                                                                 activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 64, 64, 16)   9232        concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 64, 64, 16)   64          conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_58 (Gl (None, 16)           0           batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 4)            68          global_average_pooling2d_58[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 4)            0           dense_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 16)           80          activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 16)           0           dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_53 (Reshape)            (None, 1, 1, 16)     0           activation_646[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_53 (Multiply)          (None, 64, 64, 16)   0           batch_normalization_539[0][0]    \n",
      "                                                                 reshape_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 64, 64, 59)   0           concatenate_129[0][0]            \n",
      "                                                                 multiply_53[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 64, 64, 59)   0           concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_24 (Conv2DTran (None, 128, 128, 8)  1896        activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 128, 128, 19) 0           conv2d_transpose_24[0][0]        \n",
      "                                                                 activation_530[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 128, 128, 8)  160         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 128, 128, 8)  616         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 128, 128, 8)  32          conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 128, 128, 8)  32          conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 128, 128, 8)  0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 128, 128, 8)  0           batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 128, 128, 8)  72          activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 128, 128, 8)  264         activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 128, 128, 8)  32          conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 128, 128, 8)  32          conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 128, 128, 8)  0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 128, 128, 8)  0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 128, 128, 16) 0           activation_649[0][0]             \n",
      "                                                                 activation_651[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 128, 128, 8)  1160        concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 128, 128, 8)  32          conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)             (None, 4, 4, 512)    2336768     activation_593[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_59 (Gl (None, 8)            0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchN (None, 4, 4, 512)    2048        conv2d_494[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 2)            18          global_average_pooling2d_59[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "activation_594 (Activation)     (None, 4, 4, 512)    0           batch_normalization_494[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 2)            0           dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)             (None, 4, 4, 512)    2359808     activation_594[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 8)            24          activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchN (None, 4, 4, 512)    2048        conv2d_495[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 8)            0           dense_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_595 (Activation)     (None, 4, 4, 512)    0           batch_normalization_495[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 1, 1, 8)      0           activation_653[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_54 (Gl (None, 512)          0           activation_595[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_54 (Multiply)          (None, 128, 128, 8)  0           batch_normalization_544[0][0]    \n",
      "                                                                 reshape_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 512)          0           global_average_pooling2d_54[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 128, 128, 27) 0           concatenate_132[0][0]            \n",
      "                                                                 multiply_54[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 10)           5130        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 128, 128, 27) 0           concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "landmarks_output (Lambda)       (None, 10)           0           dense_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mask_output (Conv2D)            (None, 128, 128, 1)  28          activation_654[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,752,394\n",
      "Trainable params: 21,733,866\n",
      "Non-trainable params: 18,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# layers = [10, 16, 32, 64, 128]\n",
    "# model = models.MultiTaskResNet(layers, 14, IMAGE_SIZE)\n",
    "model = TriNet()\n",
    "print(model.summary())\n",
    "\n",
    "losses = {\n",
    "    \"mask_output\": \"binary_crossentropy\",\n",
    "    \"landmarks_output\": zero_loss\n",
    "}\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss=losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\n",
    "#         '../weights/landmarks/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "#         save_best_only=True,\n",
    "#         save_weights_only=True\n",
    "#         ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='../output/logs')\n",
    "    ]\n",
    "\n",
    "model.fit(\n",
    "    images_train,\n",
    "    {\"mask_output\": masks_train, \"landmarks_output\": labels_train},\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(images_valid, {\"mask_output\": masks_valid, \"landmarks_output\": labels_valid})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second try: with a standard UNet\n",
    "\n",
    "It does not work .... ahhhhh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        tf.keras.backend.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return tf.keras.backend.mean(tf.keras.backend.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 8)  224         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 8)  584         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 8)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 16)   1168        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 16)   2320        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 16)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8, 8, 128)    0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 128)    147584      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 64)   32832       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 64)   73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 32)   8224        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 64)   0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 16)   2064        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 32)   0           conv2d_transpose_6[0][0]         \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 16)   4624        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 16)   2320        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 8)  520         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 16) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 8)  1160        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 8)  584         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 1)  9           conv2d_36[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 485,817\n",
      "Trainable params: 485,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Lambda,\n",
    "    Conv2DTranspose,\n",
    "    concatenate,\n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "# Build U-Net model\n",
    "inputs = Input(IMAGE_SIZE)\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "d1 = Dropout(0.5)(c5)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (d1)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 526 samples, validate on 132 samples\n",
      "Epoch 1/20\n",
      "526/526 [==============================] - 5s 9ms/step - loss: 43.3857 - mean_iou: 0.4202 - val_loss: 42.9663 - val_mean_iou: 0.4910\n",
      "Epoch 2/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 43.1983 - mean_iou: 0.4931 - val_loss: 42.8375 - val_mean_iou: 0.4942\n",
      "Epoch 3/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 43.0528 - mean_iou: 0.4948 - val_loss: 42.7930 - val_mean_iou: 0.4951\n",
      "Epoch 4/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 43.0025 - mean_iou: 0.4953 - val_loss: 42.7185 - val_mean_iou: 0.4955\n",
      "Epoch 5/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 42.7796 - mean_iou: 0.4957 - val_loss: 42.2039 - val_mean_iou: 0.4957\n",
      "Epoch 6/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 41.2927 - mean_iou: 0.4958 - val_loss: 40.3723 - val_mean_iou: 0.4959\n",
      "Epoch 7/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 40.7145 - mean_iou: 0.4951 - val_loss: 39.4895 - val_mean_iou: 0.4942\n",
      "Epoch 8/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 38.8399 - mean_iou: 0.4932 - val_loss: 38.6133 - val_mean_iou: 0.4926\n",
      "Epoch 9/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 37.6846 - mean_iou: 0.4922 - val_loss: 37.8692 - val_mean_iou: 0.4904\n",
      "Epoch 10/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 36.5603 - mean_iou: 0.4886 - val_loss: 36.9197 - val_mean_iou: 0.4873\n",
      "Epoch 11/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.9526 - mean_iou: 0.4846 - val_loss: 36.4732 - val_mean_iou: 0.4841\n",
      "Epoch 12/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.5880 - mean_iou: 0.4831 - val_loss: 36.8795 - val_mean_iou: 0.4823\n",
      "Epoch 13/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.7259 - mean_iou: 0.4810 - val_loss: 36.4573 - val_mean_iou: 0.4801\n",
      "Epoch 14/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.4735 - mean_iou: 0.4790 - val_loss: 37.2099 - val_mean_iou: 0.4782\n",
      "Epoch 15/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.5294 - mean_iou: 0.4762 - val_loss: 36.2017 - val_mean_iou: 0.4759\n",
      "Epoch 16/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.2833 - mean_iou: 0.4753 - val_loss: 36.2892 - val_mean_iou: 0.4750\n",
      "Epoch 17/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.1827 - mean_iou: 0.4750 - val_loss: 36.1505 - val_mean_iou: 0.4745\n",
      "Epoch 18/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.0859 - mean_iou: 0.4744 - val_loss: 36.1966 - val_mean_iou: 0.4744\n",
      "Epoch 19/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.1267 - mean_iou: 0.4741 - val_loss: 36.0864 - val_mean_iou: 0.4743\n",
      "Epoch 20/20\n",
      "526/526 [==============================] - 2s 4ms/step - loss: 35.0536 - mean_iou: 0.4746 - val_loss: 36.0147 - val_mean_iou: 0.4745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe88cf2ceb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images_train,masks_train,epochs=20,batch_size=64,validation_data=(images_valid,masks_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third try: stick more to MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "c:\\users\\guillaume\\anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x292a6c438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames = os.listdir(PATH+'resized/')\n",
    "\n",
    "test_images = np.array([sk.io.imread(PATH+'resized/' + filenames[i]) for i in range(2)])\n",
    "\n",
    "test_images = np.array([sk.transform.resize(image, IMAGE_SIZE) for image in test_images])\n",
    "\n",
    "masks_o, landmarks = model.predict(test_images)\n",
    "masks = (masks_o > 0.8).astype(np.uint8)\n",
    "\n",
    "print(masks[0].shape)\n",
    "for i in range(2):\n",
    "    mask = np.squeeze(masks[i]).astype(np.float32)\n",
    "    plt.imshow(np.dstack((mask,mask,mask)))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
