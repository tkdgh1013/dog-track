{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-e3a2a5e0a6c4>:38: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "42.22364\n",
      "79.90474\n",
      "68.53142\n",
      "35.73072\n",
      "41.04241\n",
      "40.422848\n",
      "46.27192\n",
      "38.53051\n",
      "38.346\n",
      "49.451736\n",
      "39.603355\n",
      "38.945137\n",
      "49.158913\n",
      "38.586407\n",
      "37.793037\n",
      "47.66028\n",
      "37.84593\n",
      "36.854317\n",
      "44.62905\n",
      "37.17314\n",
      "36.18241\n",
      "40.145096\n",
      "36.721535\n",
      "36.40779\n",
      "36.14724\n",
      "37.272125\n",
      "37.710934\n",
      "34.003685\n",
      "38.871506\n",
      "37.39\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DogFaceNet\n",
    "The main DogFaceNet implementation\n",
    "\n",
    "Licensed under the MIT License (see LICENSE for details)\n",
    "Written by Guillaume Mougeot\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "\n",
    "def arcface_loss(embedding, labels, out_num, w_init=None, s=64., m=0.5):\n",
    "    '''\n",
    "    :param embedding: the input embedding vectors\n",
    "    :param labels:  the input labels, the shape should be eg: (batch_size, 1)\n",
    "    :param s: scalar value default is 64\n",
    "    :param out_num: output class num\n",
    "    :param m: the margin value, default is 0.5\n",
    "    :return: the final cacualted output, this output is send into the tf.nn.softmax directly\n",
    "    '''\n",
    "    cos_m = math.cos(m)\n",
    "    sin_m = math.sin(m)\n",
    "    mm = sin_m * m  # issue 1\n",
    "    threshold = math.cos(math.pi - m)\n",
    "    with tf.variable_scope('arcface_loss'):\n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keep_dims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        weights = tf.get_variable(name='embedding_weights', shape=(embedding.get_shape().as_list()[-1], out_num),\n",
    "                                  initializer=w_init, dtype=tf.float32)\n",
    "        weights_norm = tf.norm(weights, axis=0, keep_dims=True)\n",
    "        weights = tf.div(weights, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "    return output\n",
    "\n",
    "\n",
    "# Paths of images folders\n",
    "PATH_BG = \"..\\\\data\\\\bg\\\\\"\n",
    "PATH_DOG1 = \"..\\\\data\\\\dog1\\\\\"\n",
    "\n",
    "# Images parameters for network feeding\n",
    "IM_H = 224\n",
    "IM_W = 224\n",
    "IM_C = 3\n",
    "\n",
    "# Training parameters:\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Embedding size\n",
    "EMB_SIZE = 128\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Data analysis\n",
    "############################################################\n",
    "\n",
    "\n",
    "# Retrieve filenames\n",
    "filenames_bg = []\n",
    "for file in os.listdir(PATH_BG):\n",
    "        if \".jpg\" in file:\n",
    "                filenames_bg += [file]\n",
    "\n",
    "filenames_dog1 = []\n",
    "for file in os.listdir(PATH_DOG1):\n",
    "        if \".jpg\" in file:\n",
    "                filenames_dog1 += [file]\n",
    "\n",
    "# Opens an image file, stores it into a tf.Tensor and reshapes it\n",
    "def _parse_function(filename, label):\n",
    "        image_string = tf.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image_resized = tf.image.resize_images(image_decoded, [IM_H, IM_W])\n",
    "        return image_resized, label\n",
    "\n",
    "filenames = np.append(\n",
    "        [PATH_DOG1 + filenames_dog1[i] for i in range(len(filenames_dog1))],\n",
    "        [PATH_BG + filenames_bg[i] for i in range(len(filenames_bg))],\n",
    "        axis=0\n",
    "        )\n",
    "labels = np.append(np.ones(len(filenames_dog1)), np.arange(2,2+len(filenames_bg)))\n",
    "\n",
    "# Filenames and labels place holder\n",
    "filenames_placeholder = tf.placeholder(filenames.dtype, filenames.shape)\n",
    "labels_placeholder = tf.placeholder(tf.int64, labels.shape)\n",
    "\n",
    "# Defining dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_placeholder, labels_placeholder))\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "# Batch the dataset for training\n",
    "data_train = dataset.batch(BATCH_SIZE)\n",
    "iterator = data_train.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Define the global step and dropout rate\n",
    "global_step = tf.Variable(name='global_step', initial_value=0, trainable=False)\n",
    "inc_op = tf.assign_add(global_step, 1, name='increment_global_step')\n",
    "dropout_rate = tf.placeholder(name='dropout_rate', dtype=tf.float32)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  NASNet Graph\n",
    "############################################################\n",
    "\n",
    "\n",
    "class NASNet_embedding(tf.keras.Model):\n",
    "        def __init__(self):\n",
    "                super(NASNet_embedding, self).__init__(name='')\n",
    "\n",
    "                self.pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "                self.dense_1 = tf.layers.Dense(1056, activation='relu')\n",
    "                self.dropout = tf.layers.Dropout(0.5)\n",
    "                self.dense_2 = tf.layers.Dense(EMB_SIZE)\n",
    "        \n",
    "        def __call__(self, input_tensor, input_shape=(224,224,3), training=False, unfreeze=True):\n",
    "                # base_model = KA.NASNetMobile(\n",
    "                #         input_tensor=input_tensor,\n",
    "                #         input_shape=input_shape,\n",
    "                #         include_top=False\n",
    "                #         )\n",
    "#                 base_model = tf.keras.applications.NASNetMobile(\n",
    "#                         input_tensor=input_tensor,\n",
    "#                         input_shape=input_shape,\n",
    "#                         include_top=False\n",
    "#                         )\n",
    "\n",
    "#                 for layer in base_model.layers: layer.trainable = False\n",
    "#                 x = self.pool(base_model.output)\n",
    "                x = self.pool(input_tensor)\n",
    "                x = self.dense_1(x)\n",
    "                if training:\n",
    "                        x = self.dropout(x)\n",
    "                x = self.dense_2(x)\n",
    "\n",
    "                return tf.keras.backend.l2_normalize(x)\n",
    "\n",
    "\n",
    "model = NASNet_embedding()\n",
    "\n",
    "next_images, next_labels = next_element\n",
    "\n",
    "output = model(next_images)\n",
    "\n",
    "logit = arcface_loss(embedding=output, labels=next_labels, w_init=None, out_num=len(labels))\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logit, labels=next_labels))\n",
    "\n",
    "# Optimizer\n",
    "lr = 0.01\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train = opt.minimize(loss)\n",
    "\n",
    "# Accuracy for validation and testing\n",
    "pred = tf.nn.softmax(logit)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, axis=1), next_labels), dtype=tf.float32))\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Training session\n",
    "############################################################\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "\n",
    "        summary = tf.summary.FileWriter('../output/summary', sess.graph)\n",
    "        summaries = []\n",
    "        for var in tf.trainable_variables():\n",
    "                summaries.append(tf.summary.histogram(var.op.name, var))\n",
    "        summaries.append(tf.summary.scalar('inference_loss', loss))\n",
    "        summary_op = tf.summary.merge(summaries)\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "        sess.run(init)    \n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for i in range(EPOCHS):\n",
    "                feed_dict = {filenames_placeholder:filenames, labels_placeholder:labels}\n",
    "                sess.run(iterator.initializer, feed_dict=feed_dict)\n",
    "                while True:\n",
    "                        try:\n",
    "                                _, loss_value, summary_op_value = sess.run((train, loss, summary_op))\n",
    "                                summary.add_summary(summary_op_value, count)\n",
    "                                count += 1\n",
    "                                print(loss_value)\n",
    "                        except tf.errors.OutOfRangeError:\n",
    "                                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
